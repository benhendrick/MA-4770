---
title: "MA 4780 Homework 5"
author: "Benjamin Hendrick"
date: "April 10, 2016"
output: 
  pdf_document:
    highlight: null
---

```{r, include=FALSE}
library(TSA)
```

# Exercise 7.3

Use the confidence interval equation

$$\hat{\phi}\pm z_{\alpha/2}\sqrt{\frac{(1-\hat{\phi}^2)}{n}}$$

where $\hat{\phi} = 0.7$, $\alpha = 0.05$, and $z_{\alpha/2} = 1.96$.

```{r}
phi = 0.7; z = 1.96; n= 1; a = 1; b = 0

while (a-b > 0.2) {
  a = phi + z*sqrt((1-phi^2)/n)
  b = phi - z*sqrt((1-phi^2)/n)
  n = n+1
}

n
```

In order for the confidence interval to not exceed $\pm 1$, n must equal at least `r n`. Therefore the series must be 197 lags long.

# Exercise 7.15

Simulate the AR(1) model.

```{r}
set.seed(1)
ar1 <- arima.sim(list(order = c(1,0,0), ar = c(-0.7)), n = 100)
```

## Part A

Use the `arima` function with method `ML` to find the maximum likelihood estimator of $\phi$.

```{r}
ar1.mle <- arima(ar1,order=c(1,0,0),method="ML")
```

The MLE for $\phi$ is `r ar1.mle$coef[1]`.

## Part B

Using the sample size $n=100$, we can run the `arima` function with method `ML` many times.

```{r}
mle.list <- c()
for(i in 1:1000){
  ar1 <- arima.sim(list(order = c(1,0,0), ar = c(-0.7)), n = 100)
  ar1.mle <- arima(ar1,order=c(1,0,0),method="ML")
  mle.list <- c(mle.list,ar1.mle$coef[1])
}
```

## Part C

The center of the sampling distribution is $\mu =$ `r mean(mle.list)`.

The histogram of the sampling distribution is:

```{r}
hist(x = mle.list, 
     main = "MLE for 100 AR(1) Simulations",
     xlab = "MLE")
```

## Part D

The estimators are unbiased and normally distributed because the sample size is so large. The histogram in Part C implied normality and unbias.

## Part E

The variance of the sampling distribution is $\sigma^2 =$ `r var(mle.list)`.

By 7.4.9 on Page 161 in the text, the variance should approximately be $\frac{1-\phi^2}{n} = \frac{1-0.7^2}{100} = 0.0051$.

The two variances are extremely close. The only differ by less than 0.0004.


# Exercise 7.27

## Part A
```{r}
data("oil.price")
oil.ar1.mle <- arima(oil.price, order = c(1,0,0), method = "ML") # AR(1)
oil.ar4.mle <- arima(oil.price, order = c(4,0,0), method = "ML") # AR(4)
```
The AIC for the AR(1) model is `r oil.ar1.mle$aic`. The AIC for the AR(4) model is `r oil.ar4.mle$aic`. Between the two, the AR(4) model has the smallest AIC. It would be a better model than the AR(1).

## Part B

```{r}
set.seed(23456)
oil.ma1.mle <- arima(oil.price, order = c(0,0,1), method = "ML")
```

The AIC for the MA(1) model is `r oil.ma1.mle$aic`. This is much larger than the AIC for the AR(4) model, suggesting that the MA(1) model is worse than the AR(4) model.


# Exercise 7.29

```{r}
data(robot)
```

## Part A

```{r}
robot.ar1 <- arima(robot, order = c(1,0,0))
```

The parameter(s) of the AR(1) model for the `robot` data are:

- $\phi = 0.3074$
- $\sigma^{2} = 6.482\times 10^{-6}$ 

## Part B

```{r}
robot.ima11 <- arima(robot, order = c(0,1,1))
```

The parameter(s) of the IMA(1,1) model for the `robot` data are:

- $\theta = -0.8713$ 
- $\sigma^{2} = 6.069\times 10^{-6}$ 

## Part C

The AIC for the AR(1) model in Part A is `r robot.ar1$aic`. THe AIC for the IMA(1,1) model in Part B is `r robot.ima11$aic`. 


# Exercise 8.3

For an AR(2) model, it can be shown that

$$Var(\hat{r}_{1}) \approx \frac{\phi_{2}^{2}}{n}$$

and

$$Var(\hat{r}_{2}) \approx \frac{\phi_{2}^{2} + \phi_{1}^{2}(1+\phi_{2})^{2}}{n}$$

and 

$$Var(\hat{r}_{k}) \approx \frac{1}{n} \text{ for } k \ge 3$$

By these rules:

$$Var(\hat{r}_{1}) \approx \frac{1.1^2}{200} = 0.00605$$
$$Var(\hat{r}_{2}) \approx \frac{(-0.8)^2 + 1.1^2(1+(-0.8))^2}{200} = 0.003442$$
$$Var(\hat{r}_{3}) \approx \frac{1}{200} = 0.005$$

The 95 percent confidence intervals for $\hat{r}_{1}$, $\hat{r}_2$ and $\hat{r}_3$ are 

$$\pm 2\sqrt{Var(\hat{r}_{k})} \text{ for } k = 1, 2, 3, \ldots$$

Test for individual support:

$$\pm 2\sqrt{Var(\hat{r}_1)} = \pm 2\sqrt{0.00605} = (-0.1555635, 0.1555635)$$

Becasue 0.13 is in the confidence interval, $\hat{r}_{1}$ supports AR(2).

$$\pm 2\sqrt{Var(\hat{r}_2)} = \pm 2\sqrt{0.003442} = (-0.1173371, 0.1173371)$$

Becasue 0.13 is not in the confidence interval, $\hat{r}_{2}$ does support AR(2).

$$\pm 2\sqrt{Var(\hat{r}_3)} = \pm 2\sqrt{0.005} = (-0.1414214, 0.1414214)$$

Becasue 0.12 is not in the confidence interval, $\hat{r}_{3}$ supports AR(2).

Perform a Ljung-Box test to determine joint support.

Find $Q*$, where $Q* = n(n+2)\big(\frac{\hat{r}_1^2}{n-1}+\frac{\hat{r}_2^2}{n-2}+\frac{\hat{r}^2_3}{n-3}\big)$

$$Q* = 200(202)\big(\frac{0.13^2}{199}+\frac{0.13^2}{198}+\frac{0.12^2}{197}\big) = 9.832334$$

$K = 3$, so the degrees of freedom for the Chi-Squared distribution is $K-1 = 3-1 = 2$. This gives a p-value of 0.007327. 

Therefore, we say that the autocorrelations jointly support AR(2).


# Exercise 8.6

```{r}
set.seed(34567)
ar2.sim <- arima.sim(list(order=c(2,0,0),ar=c(1.5, -0.75)),n=48)
```

## Part A

```{r}
ar2.fit <- arima(ar2.sim, order = c(2,0,0))
plot(residuals(ar2.fit), type = "o",
     main = "Residuals or AR(2) Model",
     ylab = "Residuals")
abline(h=0)
```

The model residuals don't appear to have a trend, which is to be expected.

## Part B

```{r}
qqnorm(residuals(ar2.fit))
qqline(residuals(ar2.fit))
```

The Q-Q Plot of the AR(2) model appears to have long tails and isn't normally distributed well. The model residuals should be normally distributed.

## Part C

```{r}
acf(residuals(ar2.fit), main = "ACF of AR(2) Model")
```

The ACF plot does not seems to tail off as an AR(2) plot model should.

## Part D

```{r}
set.seed(5678)
signif(acf(residuals(ar2.fit),plot=F)$acf[1:12],2)
```

The Ljung-Box test statistic where $K=12$ is 

The code below evaluates the value fo $Q*$.

```{r}
n = length(ar2.fit)
a = 0
b = signif(acf(residuals(ar2.fit),plot=F)$acf[1:12],2)

for (i in 1:12) {
  a = a + (b[i]^2)/(n-i)
}

n*(n+2)*a
```

$Q* =$ `r n*(n+2)*a`

This is with the specification of the AR(2) model.



# Exercise 8.9

We will use the `robot.ar1` and `robot.ima11` models created in Exercise 7.29 for this problem.

Plot the standard residuals for the two models.

```{r}
plot(rstandard(robot.ar1), type = "o",
     main = "Standard Residuals of AR(1) Model",
     ylab = "Standard Residuals")
abline(h=0)
plot(rstandard(robot.ima11), type = "o",
     main = "Standard Residuals of IMA(1,1) Model",
     ylab = "Standard Residuals")
abline(h=0)
```

No trend is present in either model.

Make the quantile-quantile plot for the residuals of the two models.

```{r}
qqnorm(residuals(robot.ar1))
qqline(residuals(robot.ar1))
qqnorm(residuals(robot.ima11))
qqline(residuals(robot.ima11))
```

The AR(1) model appears to be normal by the `qqnorm` plot. The IMA(1,1) model appears to have long tails by the `qqnorm` plot.

Make the ACF plots for the residuals each of the models.

```{r}
acf(residuals(robot.ar1), main = "Residuals of AR(1)")
acf(residuals(robot.ima11), main = "Residuals of IMA(1,1)")
```

The ACF for the AR(1) model has significant autocorrelations at many lags. Lags 2, 3, 5, 6, 7, 8, 9, 12, and 15 are significantly autocorrelated.

The ACF for the IMA(1,1) model has significant autocorrelation at lag 10 only.

# Exercise 8.11

## Part A

Use the AR(1) MLE and AR(4) MLE estimates of the `oil.price` data, `oil.ar1.mle` and `oil.ar4.mle`, respectively, from Exercise 7.27 for this problem.

## Part B

Use the MA(1) MLE estimates of the `oil.price` data, `oil.ma1.mle` from Exercise 7.27 for this problem.

## Part C

Plot the standardized residuals of all the models.

```{r}
plot(rstandard(oil.ar1.mle), type = "o",
     main = "Standard Residuals of AR(1) Model",
     ylab = "Standard Residuals")
abline(h=0)
plot(rstandard(oil.ar4.mle), type = "o",
     main = "Standard Residuals of AR(4) Model",
     ylab = "Standard Residuals")
abline(h=0)
plot(rstandard(oil.ma1.mle), type = "o",
     main = "Standard Residuals of MA(1) Model",
     ylab = "Standard Residuals")
abline(h=0)

```

The AR(1) and AR(4) models do not appear to have any residual trends. However, the MA(1) model has a positive trend in the residuals after year 2000.

Make the quantile-quantile plots for each model.

```{r}
qqnorm(residuals(oil.ar1.mle), main = "QQ-Plot for AR(1)")
qqline(residuals(oil.ar1.mle))
qqnorm(residuals(oil.ar4.mle), main = "QQ-Plot for AR(4)")
qqline(residuals(oil.ar4.mle))
qqnorm(residuals(oil.ma1.mle), main = "QQ-Plot for MA(1)")
qqline(residuals(oil.ma1.mle))
```

None of the models appear to be normally distributed.

Make the ACF plots for each model.

```{r}
acf(residuals(oil.ar1.mle), main = "Residuals of AR(1)")
acf(residuals(oil.ar4.mle), main = "Residuals of AR(4)")
acf(residuals(oil.ma1.mle), main = "Residuals of MA(1)")
```

The residuals for the AR(1) model have significant autocorrelation at lags 4, 5, 10, 11, 13, and 18. The residuals for the AR(4) model have significant autocorrelations at the same lags.

The residuals for the MA(1) model have significant autocorrelations for every lag.

Given the diagnostics in this part, I would select the AR(1) model. It is close to the AR(4) model, but slightly more normal. However, it is simpler than the AR(4) model.